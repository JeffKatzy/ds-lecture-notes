{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tools\n",
    "\n",
    "folium, pivottablejs, missingno, pandas_profiling, mpld3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why EDA\n",
    "    A. For the Analyst\n",
    "        ○ Let's us identify patterns and develop hypotheses\n",
    "        ○ Test technical assumptions\n",
    "        ○ Build an intuition for the data \n",
    "        § So that if you have an idea for the data\n",
    "        § Can make mistake\n",
    "    B. For the consumer \n",
    "    ○ Ensures right question is being asked \n",
    "        § Tests business assumptions\n",
    "        ○ Leads to insights that otherwise would not be found \n",
    "        ○ Provides the context for max value of the results \n",
    "II. Themes\n",
    "        ○ You are never done with EDA.  Every time you are iterating through analysis we do this.\n",
    "        ○ Stay open minded: test assumptions you might have \n",
    "        ○ Redo EDA even if on the same datasets\n",
    "III. Process\n",
    "\n",
    "A. Prepare\n",
    "\n",
    "    1. Form Hypotheses\n",
    "    2. Wrangle Data\n",
    "    3. Assess Data Quality and Profile\n",
    "    4. Explore each variable in the dataset\n",
    "\n",
    "B. Analysis  \n",
    "    5. Assess relationship between each variable and the target (the thing of interest, eg. why people churn in your website)\n",
    "    6. Assess interactions between variables\n",
    "    7. Explore data across many dimensions\n",
    "    \n",
    "This feels linear, but really each of these steps have branches, so need to come back to these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### approaches\n",
    "\n",
    "* Before plotting or joining, have a question or hypothesis in mind.  Write it down.  \n",
    "* Draw a plot of what you want to see on paper to sketch the idea.\n",
    "* How do you know you are not fooling yourself?\n",
    "    * What else can you check that it's actually true?\n",
    "    * What evidence could there be that it's wrong?\n",
    "    \n",
    "* What is the unit economics of the question? JK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we answer the question of whether referees give more red cards to dark skinned players?\n",
    "  > More likely to give a yellow or no card for the same offense under the same conditions?\n",
    "  \n",
    "Potential issues: \n",
    "\n",
    "* Conflicting data:  How to combine rater 1 and 2 of skin tone?  \n",
    "* Is data imbalanced:  Red cards very rare?\n",
    "* Is data biased: players with different amounts of playing time?\n",
    "    * Perhaps unit economics helps with this\n",
    "* How do I know if I accounted for all forms of confounding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas \n",
    "1. Look at the shape of the data. \n",
    "A. Is there a data dictionary?  Begin to understand this.\n",
    "B. **Pandas commands**\n",
    "\n",
    "    df.shape() \n",
    "        * To see the number of rows and columns\n",
    "   df.columns.to_list()\n",
    "   df.head()\n",
    "       * To see the first few elements\n",
    "   df.describe().T\n",
    "       * .T to transpose the data\n",
    "       * Count, mean, std, min, etc.\n",
    "   df.dtypes \n",
    "       * To see all of the datatypes of the data\n",
    "       \n",
    "   data.info()\n",
    "       * can tell you what types of data there is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy data\n",
    "\n",
    "* Each variable forms own column\n",
    "* Each observation forms row\n",
    "* Each type of observational unit forms a table\n",
    "\n",
    "1. Make a players table \n",
    "    * He does this with `groupBy` of the index, like players name\n",
    "        * Sees if data is consistent among all by doing agg('unique')\n",
    "    * And get what is unique to each player\n",
    "        * Height, weight, name, position, rater1, rater2\n",
    "\n",
    "* Now once we have the players table, can save by doing `to_csv`, and test it saved via `read_csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`countries.rename(columns={'old_name': 'new_name'})` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now working with one table\n",
    "\n",
    "1. Handle Missing Data\n",
    "2. Combining/removing columns\n",
    "3. Distributions \n",
    "4. Correlations\n",
    "\n",
    "    * Is data unbalanced? (What does this mean?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate data \n",
    "\n",
    "`nunique`\n",
    "`drop_duplicates()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore missing data \n",
    "\n",
    "Is there systematic reason for the data missing, or is it randomly missed?\n",
    "    * Eg. fields always missing at the same time?\n",
    "    * Eg. data missing for a whole group of people\n",
    "\n",
    "* can use missing no library \n",
    "    * To see amount of data missing per each column\n",
    "    * To see correlation of missing data btwn columns \n",
    "    * Do a heat map to see how correlated is the missing data \n",
    "\n",
    "A. Start with a count by columns\n",
    "    Why are some entire categories empty?  \n",
    "    Why are some much more than others, etc.\n",
    "    ```python\n",
    "    recent = time_slice(data, '2013-2017')\n",
    "    msno.bar(recent, labels=True)\n",
    "    ```\n",
    "B. Then move onto matrix \n",
    "\n",
    "    *`msno.matrix(recent, labels=True)`\n",
    "    \n",
    "* So now can see the correlation between missing data variables \n",
    "* Is there a pattern of missingness, as opposed to random missing data \n",
    "\n",
    "Some categories are just missing entirely - so can look into them.  Did that data get mixed into other categories, or datasets?\n",
    "\n",
    "* Select say, all countries in north america, then call `nullity_sort`, to sort by missingness of data.  \n",
    "  * Take a look at what downey says about removing missing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backlog for missing data \n",
    "\n",
    "* Assess the prevalence of missing data across all data fields, assess whether its missing is random or systematic, and identify patterns when such data is missing\n",
    "* Identify any default values that imply missing data for a given field\n",
    "* Determine sampling strategy for quality assessment and initial EDA\n",
    "* For datetime data types, ensure consistent formatting and granularity of data, and perform sanity checks on all dates present in the data.\n",
    "* In cases where multiple fields capture the same or similar information, understand the relationships between them and assess the most effective field to use\n",
    "* Assess data type of each field\n",
    "* For discrete value types, ensure data formats are consistent\n",
    "* For discrete value types, assess number of distinct values and percent unique and do sanity check on types of answers\n",
    "* For continuous data types, assess descriptive statistics and perform sanity check on values \n",
    "* Understand relationships between timestamps and assess which to use in analysis\n",
    "* Slice data by device type, operating system, software version and ensure consistency in data across slices\n",
    "* For device or app data, identify version release dates and assess data for any changes in format or value around those dates\n",
    "\n",
    "#### Taking action on missing data \n",
    "\n",
    "* count amount of missing data\n",
    "`data.isnull().values.sum()`\n",
    "\n",
    "1. Ignore that there's missing data\n",
    "2. Remove the missing data\n",
    "    - Can drop any existence of not a number\n",
    "    `.dropna(), any row with nan gets removed`\n",
    "    - Now say we want to remove only rows that have all NAN\n",
    "    `data.dropna(how=\"all\")`\n",
    "    - also can use threshold, where if it has certain amounnt of NAN then remove \n",
    "    Forward fill data - take data and sweep it forward `fillna(method=\"ffill\")`\n",
    "    And back fill via `fillna(method=\"bfill\")`\n",
    "3. Fill in the missing data\n",
    "    `fillna(value=9999)`\n",
    "4. Replace missing data with a static number\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing data\n",
    "\n",
    "1. Cross section - one time period across all of the dataset \n",
    "2. Time series - a single country over time \n",
    "3. Geospatial - grouping similar data (by feature), eg. grouping by region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of data\n",
    "\n",
    "* `pd.get_values` ? to get a histogram of the data\n",
    "* creating bins for continuous variables\n",
    "    * `pd.qcut(players['weight'], len(categories), weight_categories)`\n",
    "To get a distribution:\n",
    "* `sns.distplot(players.age_years)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See correlation btwn data \n",
    "\n",
    "For example, how much do the two ratings differ\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "sns.heatmap(pd.crosstab(players.rater1, players.rater2), cmap='Blues', annot=True, fmt='d', ax=ax)\n",
    "ax.set_title(\"Correlation between Rater 1 and Rater 2\\n\")\n",
    "fig.tight_layout()\n",
    "```\n",
    "\n",
    "Can see that no rating is more than 2 away.\n",
    "\n",
    "And now that we see they are very similar, we can combine the two columns just by taking the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that have cleaned data, time to explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So can see a distribution of the redcards across skintone\n",
    "\n",
    "Can see if there are any lurking variables \n",
    "    1. Is skintone correlated with anything else?\n",
    "    2. Are redcards correlated with anything else?\n",
    "Scatter matrix: \n",
    "\n",
    "Will create all of the cross terms\n",
    "\n",
    "```python\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "scatter_matrix(players[['height', 'weight', 'skintone']], alpha=0.2, diagonal='hist', ax=ax);\n",
    "\n",
    "```\n",
    "\n",
    "* Note that the diagonal always creates a 1 to 1, so he does that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also can just get to just comparing two of the attributes.\n",
    "\n",
    "\n",
    "```python\n",
    "fig, ax = plt.subplots(figsize=MIDSIZE)\n",
    "sns.regplot('weight', 'height', data=players, ax=ax)\n",
    "ax.set_ylabel(\"Height [cm]\")\n",
    "ax.set_xlabel(\"Weight [kg]\")\n",
    "fig.tight_layout()\n",
    "\n",
    "```\n",
    "\n",
    "For correlation, can do `df.corr()`, and will give correlation for all of the columns\n",
    "The `corr()` returns a dataframe, so we can call `describe` on the correlations as well to see where most correlation occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then library to get a high level overview \n",
    "\n",
    "* https://github.com/JosPolfliet/pandas-profiling\n",
    "`pandas_profiling.ProfileReport(players)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can further clean \n",
    "* So have a list of the subset of columns you want, and then once have cleaned table, can profile again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps \n",
    "* Task perform on referee, clubs, and country dataframe\n",
    "    1. Handle Missing Data\n",
    "    2. Combining/removing columns\n",
    "    3. Distributions \n",
    "    4. Correlations\n",
    "* Do redcard final joins, to see analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "> Can see dataset with fivethirtyeight article, science isn't broken \n",
    "> * [EDA](https://www.youtube.com/watch?v=W5WE9Db2RLU)\n",
    ">*  [Handling Missing Data](https://www.youtube.com/watch?v=O5v4NrSCw_A&list=PLQVvvaa0QuDc-3szzjeP6N6b0aDrrKyL-&index=10)\n",
    "> * [Missing data](https://github.com/ResidentMario/missingno)\n",
    "> [Quandl dataset](https://www.quandl.com/docs-and-help)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
